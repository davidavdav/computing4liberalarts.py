\documentclass[a4paper,11pt]{article}
\usepackage{fullpage} %% part of the preprint page
\usepackage{url}
\usepackage{enumitem}
\usepackage{verbatim}
\usepackage{framed}
\usepackage{xcolor}
\usepackage[lastexercise]{exercise}
\usepackage{graphicx}

\setenumerate{itemsep=0pt, parsep=0pt}

\renewcommand\ExerciseHeader{\noindent\textbf{\ExerciseName~\ExerciseHeaderNB} ---}
\newenvironment{exercise}{\csname shaded*\endcsname \Exercise} {\endExercise\csname endshaded*\endcsname}
\definecolor{shadecolor}{gray}{0.95}
\definecolor{answercolor}{rgb}{0.9,0.9,1}
\newenvironment{answer}{\Answer\def\FrameCommand{\colorbox{answercolor}}\MakeFramed{\advance\hsize-\width\FrameRestore}}{\endMakeFramed\endAnswer}

\def\fig#1{Fig.~\ref{fig:#1}}
\def\sec#1{Section~\ref{sec:#1}}
\def\tab#1{Table~\ref{tab:#1}}
\def\eq#1{(\ref{eq:#1})}
\def\Eq#1{Equation~\eq{#1}}
\def\ex#1{exercise~\ref{ex:#1}}

%% make \_ math-mode dependent
\let\underscore=\_
\def\_{\checkmath_\underscaore}
\def\checkmath#1#2{\ifmmode\def\next##1{#1{\rm##1}}\else\let\next=#2\fi\next}

%% automatic math mode
\def\math#1{\relax\ifmmode#1\else$#1$\fi}

\def\tilde{\char`\~}
\let\pipe=|
\catcode`\|=\active
\def|#1|{\ifmmode\hbox{\texttt{#1}}\else\texttt{#1}\fi}
\def\<#1>{\ifmmode \langle\hbox{\textrm{\textit{#1}}}\rangle\else$\langle\hbox{\textrm{\textit{#1}}}\rangle$\fi}

\def\sn{\emph{Sprekend Nederland}}

\title{Assignments in R: The ``Sprekend Nederland'' database.}
\author{David van Leeuwen}
\date{7 jan 2016}

\begin{document}

\maketitle

\section{Introduction}

``Sprekend Nederland'' is a project that collects spoken accents in The Netherlands, as well as opinions about these accents.  It launched in December 2015, and is currently still going on---if you can speak Dutch you are invited to participate, see \url{http://www.ntr.nl/sprekendnederland}.  

The actual data (the audio recordings, answers to all opinion questions), as well as metadata about the participants are all collected in a big relational database.  Working with databases is rather complicated, and far beyond the scope of this course.  However, the data itself gives us a great opportunity to think about how data is stored, and how we can extract the data in a meaningful way. 

In the Sprekend Nederland app, each participant is asked to answer questions.  Most of these are about other participants, and the answers are expected to be based on the accent or speaking style of the speaker.  Some questions are \emph{metadata questions} about the participant herself.  The participant is also requested to speak in a number of sentences herself, and this data is then used in subsequent sessions of other participants.  After some period (a week or so), enough answers are given about the participant's sentences that allow some feedback to this participant.  The idea is that this is an incentive for people to participate.  There are many questions, and many participants (potentially millions, there is no restriction other than that a participant should understand Dutch), so not everyone can listen to everybody and answer all questions about this person.  This makes the database relatively sparse and heterogeneous, but hopefully it will be large enough for answering some interesting research questions. 

For this assignment, we work with fresh data obtained from a download in December~2015.  Nobody else has analyzed the data yet, so please don't succumb to the coolness of this all. 

\subsection{Preparation}

On the course website \url{https://sites.google.com/site/ucaccmeth2} (a.k.a.\ ``Meth Lab'') you will find a directory |Data sets/Sprekend Nederland|.  Download the files in that folder to your own computer in a place you're comfortable with.  Choose a place that is ``easy to reach'' in you local OS's sense, i.e., not tucked away too deeply in obscure places with ancestor folder names with weird characters in it.  You'll probably have to type that path, soon. 
 
Open a command shell of your leisure, and change your working directory so that these files are available. 

The data is organized in so-called ``tables.'' A table is a collection of ``records,'' a set of values belonging to the same item.  It is probably easiest to just have a quick look into the data.  

For this assignment, we've collected some relevant data in the table |answers.csv|. Let's first inspect the file using |less|:
\begin{verbatim}
$ less answers.csv
\end{verbatim}
Remember, you can move about using \<space> to scroll down, and |b| to scroll back, and you exit the inspection with |q|.  You can see that the first line contains a `header,' an indication of the names of the columns in the table.  The lines after that contain the data records.  
\begin{exercise}
  Use your proviously obtained skills with the command line to quickly find out the following quantities (|cat|, |wc| and |grep| are you friends).  If |bash| or the equivalent PowerShell commands are not available, skip this question, and offer a bounty of some kind to a person who can provide you with the answers.  
  \Question{How many answers does the table |answers.csv| contain?}
  \Question{How many answers are given to question |q53|?}
  \Question{How many answers are given to questions that are about a ``droomhuis''?}
  \Question{How many answers are given to questions that are \emph{not} of the type ``slider''? (Look at column |atype|)}
\end{exercise}
\begin{answer}
  \begin{enumerate}
  \item $393657 - 1 = 393656$ (one for the header)
  \item |cat tables/answers.csv \pipe\ grep q53 \pipe\ wc| gives 11395 lines .\item |cat tables/answers.csv \pipe\ grep droomhuis \pipe\ wc| gives 10966 lines
  \item |cat tables/answers.csv \pipe\ grep -v slider \pipe\ wc| gives 87425 lines
  \end{enumerate}
\end{answer}
\section{Descriptive statistics: mucking about with the data}

Now this is all nice and quick (in principle, when you have got used to the bash command line and everything), but it isn't very structured, or even exact (did you think of not counting the header line?).  It is better to do this in an environment that is designed for these kind of quick analyses.  And we will use ``R'' for that. 

Reading in the data in \emph{any} computing environment can be a bit of a chore.  Other modules in this course will teach you how to fix small problems in case data is missing, or badly formatted, or whatever.  For this assignment, however, we've fixed the table so that it can be read quite painlessly into R.  Start R by (possibly first downloading it by searching for ``R project'' on the web and then) clicking the appropriate icon, or by typing
\begin{verbatim}
$ R
\end{verbatim}
If you clicked an icon, you end up with a sort-of-graphical interface, where the main piece of real estate is\dots a command window.  Now, the most painful operation has to happen, namely, you have to convince R to change its \emph{current working directory} to where your data is located.  Type in the command window (remember, the |>| represents R's prompt, you should not type this, and neither should you type anything from |\char`\#| onwards, this indicates it is a comment):
\begin{verbatim}
> setwd("d:/path/to/where/you/put/these/files") ## tell R where the files are
\end{verbatim}
Then, if everything went fine, the following command should produce some output:
\begin{verbatim}
> read.csv("answers.csv") ## read file "answers.csv", and make a dataframe
\end{verbatim}
Whoops---that is a lot of rows (we knew that), and even R finds that too many to display. And the information is lost.  Let's store this in an \emph{object} (a.k.a.\ a variable):
\begin{verbatim}
> x <- read.csv("answers.csv") ## same, but save the result in variable `x`
\end{verbatim}
That probably took a while, but where is the result gone?  It is in the object |x|.  We say that the \emph{function} |read.csv()| produces an object that is known as a Dataframe, and is stored in |x| by the \emph{assignment operator} |<-|.  We can inspect the Dataframe by looking at the first few rows:
\begin{verbatim}
> head(x) ## show only the first few lines of `x`
\end{verbatim}
This shows the first few rows, or records, of the Dataframe.  You can maybe appreciate that R automatically assigned column names to the table.  That's great.  But otherwise, you might find that some information, e.g., the column |prompt|, is formatted a bit awkwardly.  Also, each row is prepended on the left with a `row number'.  This information is not in the original CSV data itself, but can help to identify a specific row---row numbers (or names) are unique within the Dataframe. 

The function |read.csv()| did more than just reading in the data.  It took a guess at the type of data, and recognized that the question-ID column |qid| consists of character strings, whereas the listener-ID |lid| is an integer number.  

Let's inspect the data in |x|.  One of the most useful functions in R, I think, is |table()|, which computes a \emph{contingency table}:
\begin{verbatim}
> table(x$qid) ## count how often each value in `x$qid` occurs
\end{verbatim}
This counts how many aswers are given per question.  Does the number for |q53| look familiar?  The command you just typed uses the |\$|-notation to indicate a specific \emph{column within |x|}.  The column |x\$qid| only contains the question-ID's |q53|, |q54|, etc, and not any of the other data in the table. 

The |table()| function figured out the available values in the data frame---in fact, secretly, |read.csv()| had already done this---the available values are called the \emph{levels} of the \emph{factor} |qid|.  This is just nomenclature used by statisticians.  

Still, this is not very insightful---you just see a whole lot of numbers on the screen.  But you can visualize a table, by using the general-purpose workhorse |plot()|:
\begin{verbatim}
> plot(table(x$qid)) ## make a graph about the `table`
\end{verbatim}
Somewhere on the screen a graph should pop up.  It show bars for each question-ID for which the length is indicative of the amount or rows in the Dataframe matching this question.  Now this is a lot quicker than various |grep| and |wc|'s!  Inspecting the command you typed, you see the characteristic ``mathematics'' notation of operations: the data starts at the innermost level (|x\$qid|) and then the operation ``construct a table'' is applied to the data, and finally the operation ``make a graph'' is in turn applied to the table that was constructed.  Just in case you wonder, the table was made, then used for the plot, and finally thrown away---maybe you think this is a bit of a waste of computing resources, but the advantage is you don't have to do any tidying up yourself!

\begin{exercise}
  Tables with really \emph{lots} of levels\dots
  \Question{Make a plot of the distribution of answers over \emph{listener-IDs} |lid| (the persons who answered questions).  Is there anything remarkable?}
  \Question{Do the same for the \emph{speaker ID} data in column |sid|.} 
  \Question{The same IDs for listeners and speakers refer to the same people---in \sn\ participants function both as speaker and listener.  The ID-numbers are assigned to participants in order of registration.  Can you explain the global shape of the last graph?}
\end{exercise}
\begin{answer}
  \begin{enumerate}
  \item |plot(table(x\$lid))|  Around 3000 there is someone who did \emph{a lot} of ansswers
  \item |plot(table(x\$sid))|
  \item A speaker is chosen randomly from the available speakers. The early participants were available for more listeners to be chosen randomly, this explains the decreasing density with higher participant number. 
  \end{enumerate}
\end{answer}

A really quick overview of all information in a Dataframe is the |summary()| function.  Depending on the type of data, R does a different type of global statistics analysis.
\begin{verbatim}
> summary(x) ## make a summary of anything that is to be found in `x`
\end{verbatim}
For some columns, e.g., |atype| and |utype| you get summary information similar to |table()|, but for instance for |sid| you see that the fact that the data is numeric confuses R a bit.  In this case, a |table()|-like analysis would have made more sense than the mean and median of the numbers---remember, these are just IDs, they have no scalar interpretation.  But you can get a quick idea what the values of |atype| (answer type) and |utype| (utterance type) are, and their counts.  

The real power of |table()| is revealed when you give it multiple arguments:
\begin{verbatim}
> table(x$atype, x$utype) ## cross-tabulate `x$atype` en `x$utype`
\end{verbatim}
The tables is now in a matrix form, and each number indicates how many answers are given with a specific answer type about a recording of a specific utterance type.  
\begin{exercise}
  \Question{Plot the 2-dimensional table above.  How do you think you should interpret what you see?}
  \Question{Investigate the table-interaction between column |qlist| (question list) and either |atype| or |utype|.  Which of the two shows a dependency between the two columns?}
  \Question{Use |table()| to find out if there is a dependency between the question-ID |qid| and the answer-type |atype|.}
\end{exercise}
\begin{answer}
  \begin{enumerate}
  \item |plot(table(x\$atype, x\$utype))| Areas are proportional to counts
  \item |table(x\$qlist, x\$atype)| no special interaction,  |table(x\$qlist, x\$utype)| strong dependence, the |qlist| determines |utype|. 
  \item |table(x\$qid, x\$atype)|, the |qid| determines |atype|.
  \end{enumerate}
\end{answer}
\subsection{Working with the attitude judgements}

So far, we've just looked at how our data points (the rows in the Dataframe) are distributed w.r.t.\ some metadata about the points. But we haven't looked at what the Dataframe actually tries to store: the answers to certain questions.  
The answers given by the participants are actually stored (mostly) in the column |value|.  If you do a |summary(x\$value)| you'll notice that the recorded values vary quite a bit over all answers.  But you can also see that most answers are a number in the range 1--7: this is because most questions had a response option of a seven-point scale on a slider.  

Let's first work with a question, |q53|, for which the actual question happened to be ``Vind je deze persoon intelligent?'' (Do you think this person is intelligent?).  The answer given by |lid| about the speaker |sid| speaking the text in |prompt| would be recorded in a 7-point slider position, where |1| represents ``not at all'' and |7| represents ``very much so''.  

The problem now is that all answer-types (7-point scales, but also birth years and even location coordinates) are all `mixed' in the column |value|.  Perhaps not ideal, but this simply is how the data was stored in the database. 

With R it is quite easy to make a sub-selection of the data in a dataframe.  The function is called |subset()|, and I believe it is the second most handy function, after |table()|.  
\begin{verbatim}
> y <- subset(x, qid=="q53") ## select rows from `x` for which `qid` is "q53"
\end{verbatim}
Unimaginatively, I called the subset of rows that belong to question 53 ``|y|''.  The |subset()| function does something that very few other programming languages can do: it accepts |qid| in its second argument even though that formally doesn't exist on its own---the function |subset()| actually knows how to combine the |x| from the first argument to know that |qid| refers to a column \emph{inside} the dataframe |x|.  |subset()| further selects rows for which its |qid| value is equal (hence the |==|, we've seen this in Python as well) to the character string ``|q53|''.  

With |nrow(y)| you can find out how many answers are in the Dataframe---this should be consistent with what we learned from |table(x\$qid)|.  
\begin{exercise}
  Divide the number of rows in |y| by the number of rows in |x| using the division |/|, to find out what fraction of the answers were about |q53|. 
\end{exercise}
\begin{answer}
  |nrow(y) / nrow(x)| results in 0.02894659, or about 2.8\,\%
\end{answer}
We're supposed to do something with the participant's judgements about other participants on the question |q53|---remember these were encoded as a number ranging from 1 through 7.  So first have a look at the distribution of values. 
\begin{verbatim}
> table(y$value)
\end{verbatim}
What hapened here?  The output might baflle you a bit, and quite understandably so.  Instead of a table ranging 7 values, we got a list of all kinds of values, most of which exactly 0 times.  Not very handy.  For this particular data set, it is a result of the way the different kinds of possible answers (1--7, a birth year, yes/no, a location) were all put in the column |value|.  In going from |x| to the subset |y|, R `remembered' there were also other possible answers around.  

In dealing with various forms of data and subset in R, this sometimes happens.  It is annoying, and you'll need to find a way out.  Here, we'll suffice with just showing the solution for this case:
\begin{verbatim}
> y$value <- as.numeric(as.character(y$value)) ## force `value` to be numeric
> table(y$value)
\end{verbatim}
This is more like it.  The values are now just interpreted as \emph{numbers}.  (Technically, what we're going to do next is statistically not correct, because the value judgements were not numbers, but levels like ``not at all'', ``just a little'', etc.  But for the sake of doing stuff with R, we'll go along anyway). 

\begin{exercise}
  \label{ex:mean-q53}
  We're going to work with the values for |q53|. % Store these in an object |v| by assigning (|<-|) the column |y\$value| to |v|.  
  \Question{Using the functions |mean()|, |median()|, |sd()|, |min()| and |max()| compute the mean, median, standard deviation, minimum and maximum of the values |y\$value|.}
  \Question{Plot the table for |y\$value|, using plain |plot()| and |barplot()|.  Which one do you find prettier?}
\end{exercise}
\begin{answer}
  \begin{enumerate}
  \item |mean(y\$value)| is 4.119614, |median(y\$value)| is 4, |sd(y\$value)| is 1.316707, |min(y\$value)| is 1, |max(y\$value)| is 7.
  \end{enumerate}
\end{answer}
We're going back to analyzing multiple questions at the same time.  We'd like to look at the questions |q53| through |q74|, since these are all answered on a 7-point scale.  We need to make a subset of |x| again, but allow more values for |qid|.  There are some more R basics we need to use for this: the sequence operator ``|:|'', the string joining function |paste()| and the set operator |\%in\%|. 
\begin{verbatim}
> sevens <- paste("q", 53:74, sep="") ## `sep` is a named argument
> sevens
\end{verbatim}
The last statement---an object on is own without function or assignment---displays the value of the object  In this case, we check what the result is of the |paste()| function above.  This result is a \emph{vector} of values, i.e., whole sequence, not just a single value.  In R, everything that is a vector is prepended by the element index, starting at |[1]|, for each row that is displayed. (R does so, even if there is only a \emph{single} value, you may find that somewhat confusing in the beginning.)  The values of |sevens| are there for the strings ``|q53|'', ``|q54|'', etc. through ``|q74|''.
\begin{exercise}
  \Question{Look up what ``|:|'' does by typing |?":"| at the prompt.  You should be directed to some help on |:|.  Can you figure from all of this out what |paste()| does?}
\end{exercise}
\begin{answer}
  |paste(a, b)| takes elements in ``|a|'' and glues them to elements in ``|b|''.  These elements can be strings, or numbers.  The elements in |a| line up with those in |b|. In our case, |a| was just a single element |"q"|, so it was paired multiple times, with the number 53, 54, \dots, 74.  The result is a vector of strings. 
\end{answer}

Now we can repeat the |subset()|, but with a different condition:
\begin{verbatim}
> y <- subset(x, qid %in% sevens) ## %in% is TRUE if `qid` is one of `sevens`
> nrow(y)
\end{verbatim}
The condition |qid \%in\% sevens| is true for any row in Dataframe |x| for which the question-ID |qid| is one of the IDs found in the vector |sevens|.  Notice that we are re-assigning the result of the new |subset()| to an existing variable |y| that you made earlier.  Whatever was in there, is now lost, gone forever (but we can always regenerate the subset if we wish).  
\begin{exercise}
  Re-apply the normalizing statement to |y\$value| like you did earlier.  You can save typing by pressing the up-arrow key multiple times, until you see the |...as.numeric(as.character(...))| statement.  Then simply press \<enter> to execute the statement.  Check afterwards that the values of the new |y| behave properly. 
\end{exercise}
\begin{answer}
\begin{verbatim}
y$value <- as.numeric(as.character(y$value))
table(y$value)
\end{verbatim}
The |table()| will show you that there are no stray levels left. 
\end{answer}

\subsection{The formula interface}

Suppose we would want to analyse the mean of |value| for the different questions |qid|.  For |q53| we have just done that ``manually'' above, but it would be awkward if we'd have to do this for all questions.  There is another powerful function that can help us here 
\begin{verbatim}
> aggregate(value ~ qid, y, mean) ## does complicated things
\end{verbatim}
The result is another Dataframe, with a column |qid| and |value|, which is the \emph{mean} of all |y\$value| for the specific |qid|.  The function |aggregate()| uses the so-called \emph{formula interface} here in the first argument.  Roughly, it looks like
\begin{equation}
  \label{eq:1}
  \<dependent variable> \sim \<independent variable> [ + \cdots ]
\end{equation}
This means that the variable |value| is modeled as depending only |qid|.  The `model' in this case is pretty simple---it is just the mean, as specified by the 3rd argument.  Like we saw in |subset()|, the variables specified in the formula, |value| and |qid|, ``look inside'' the dataframe |y|.  

\begin{exercise} The odd one out
  \Question{Check that the mean for |q53| is the same as calculated before}
  \Question{Browsing through these means, can you identify the question with unusual response?}
  \Question{Plot a |table()| of |qid| and |value| on the subset |y|.  To make it prettier, add a second argument |col=rainbow(7, start=0, end=1/3)| to the plot command.  Is the picture consistent with the previous answer?}
  \Question{The plot showed some ugly stuff on the right.  Just like the column |value|, the column |qid| `remembered' that there were more questions than |q53| through |q74| in the original |x|.  You can reset these using
\begin{verbatim}
y$qid <- factor(y$qid)
\end{verbatim}
    Do this, and make the plot again.  Does it improve?}
  \Question{Instead of the mean, compute the median for all questions.}
  \Question{Look up the actual question text in the file ``|questions.txt|''.  Do you understand the answers now?}
\end{exercise}
\begin{answer}
  \begin{enumerate}
  \item The first row shows as (mean) |value| 4.119614, this is the same as in the answer of exercise~\ref{ex:mean-q53}. 
  \item That would be |q66|, it has a very low mean (2.7).
  \item |plot(table(y\$qid, y\$value), col=rainbow(7, start=0, end=1/3))| The question |q66| has much more ``red'', i.e., low numbers. 
  \item The ``empty'' boxes at the right disappeared.
  \item |aggregate(value \tilde\ qid, y, median)| Also here |q66| is exceptionally low with a median of~2.
  \item In another window, look at the contents of the file |questions.txt|.  Lazy people type |cat questions.txt \pipe\ grep 66|.  The question is ``Hoe graag zou je deze persoon willen hebben als je liefdespartner''.  Google translate this: ``How badly do you want this person as your love partner''---which probably isn't that bad a translation.  Speakers and listeners were randomly coupled.  There is an almost 50\,\% chance you are coupled to someone of a sex you're not particularly interested in.
  \end{enumerate}
\end{answer}

Often, the more complicated functions in R have a formula interface.  For instance, 
\begin{verbatim}
> boxplot(value ~ qid, y)
\end{verbatim}
shows a so-called `box plot' which shows median, first and third quartiles, and indications of extremes within a distribution.  Many of the statistical analysis functions in R also use this formula interface, typically with more terms on the right-hand side of the |\tilde|, thereby specifying more factors and optionally interactions between these factors. 

\section{Some more cool graphs}

We can do more serious statistics, but statistics is boring, and moreover, we don't want steal the serious researcher's thunder who are supposed to research this data. 

Rather, let's make some graphs.  We'll use the same data.  You may have noticed, that there is a answer-type |location|.  These were answers where people could point on the map.  For instance, |q75|, ``where does this speaker come from?''

\begin{exercise}
  Select rows from |x| whose |atype| column is equal to |"location"|, and store this in a variable called ``|z|''. 
\end{exercise}
\begin{answer}
\begin{verbatim}
z <- subset(x, atype=="location")
\end{verbatim}
\end{answer}

If you look at |z\$value| you see that this is a weird encoding.  For those of you familiar with GPS devices and who simultaneously are a bit nerdy, you might recognize that these numbers look like longitude / latitude values.  For those of you who are not: these numbers look like longitude / latitude values.  The reason they are weirdly formatted is because they had to fit together in a single value (namely, the column |value|)

We'd like to split this into separate numbers.  It is possible, but is far beyond the scope of this course.  So I've included the file |ana.R| that will help you.  You can process the contents of the file, by typing
\begin{verbatim}
> source("ana.R") ## read the contents of "ana.R", as if you typed it yourself
\end{verbatim}
Now you should have a function |splitlocation()|.  We can try it on |z\$value|:
\begin{verbatim}
> loc <- splitlocation(z$value) ## a function defined in ana.R
> head(loc)
\end{verbatim}

We can now combine these three columns with the original |z|:
\begin{verbatim}
> z <- cbind(loc, z) ## bind `loc` and `z` column-wise
> head(z)
\end{verbatim}
Note that we create a new, wider data frame with |cbind()|, and then overwrite the old value of |z|.  This is a common pattern in programming. 

\subsection{Using libraries or packages}
\label{sec:using-libraries-or}

So far, we've done all the work ourselves.  But in R, like in Python, there are tremendously many packages available that will do useful things, written by people who like to share their efforts to the community.  We're going to use such a package, but this must be downloaded first. 
\begin{verbatim}
> install.packages("ggmap")  ## download a new package
> library(ggmap) ## and use it
\end{verbatim}
The package |ggmap| can do stuff with plotting on maps.  I found it somewhere on the web, and it is built on some type of advanced plotting system in R.  We'll not go into details how it works, just show you some commands. 
\begin{verbatim}
> map <- get_map(location = "Netherlands", zoom=7) ## download a map
> ggmap(map) + geom_point(data=z, aes(x=long, y=lat), size=2)
\end{verbatim}
\begin{exercise}
  \Question{Look at the last command, and experiment what the |size=2| parameter to |geom\underscore point()| does.} 
  \Question{See if you can figure our a way that it plots only the datapoints for the speaker with |sid| equal to 2}
  \Question{You can also add a parameter |col=| to the command, and set it to an integer value.  See what it does.}
\end{exercise}
\begin{answer}
  \begin{enumerate}
  \item |size| controls the size of the dots
  \item 
\begin{verbatim}
|ggmap(map) + geom_point(data=subset(z, sid==2), aes(x=long, y=lat), size=2)|
\end{verbatim}
  \item It sets the color of the dot, 1: black; 2: red, 3:green, etc.
  \end{enumerate}
\end{answer}

\subsection{Final assignment for the day}

\begin{exercise}
  You've been introduced to a couple of concepts and functions.  You've worked with a Dataframe, you can do quick counts and select certain rows according to certain selection conditions.  You have seen how to apply simple and more complicated functions.  
  
Now, given what you've seen of the data, and what you have seen of R up to now, can you think of an interesting question that you think is possible to answer with R?  For instance, the question ``Which participant seems to have the strongest accent, and where does she live?'' could be answered with the data you have, with maybe one or two additional R functions you haven't been introduced to yet.  

I'f you've come up with a question, let us know, and we'll see whether this can be done in the remaining time.  We'll give hints about available functions and a strategy towards answering the question.
\end{exercise}

\end{document}
